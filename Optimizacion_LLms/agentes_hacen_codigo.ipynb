{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QdvvQX8Pr2eo",
        "outputId": "9e59ef05-02cb-4e57-bbce-8a303327aa1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.10)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n"
          ]
        },
        {
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-f5e2aa9e503d>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"La fecha de hoy es 2024-07-02. b vale 9.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mrespuesta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_query_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrespuesta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f5e2aa9e503d>\u001b[0m in \u001b[0;36mprocess_query_with_context\u001b[0;34m(consulta, contexto)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_query_with_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconsulta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{contexto}\\n**Usuario:** {consulta}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPO54egWvLo-"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[{\"role\": \"user\", \"content\": \"cuanto vale b?\"}],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLCE0GPKsMTw",
        "outputId": "15e9887a-f1d2-4ebc-c023-3eea4b77a1bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ya has mencionado que \\( b \\) vale 9. Entonces, \\( b = 9 \\).\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Inicializar el cliente de OpenAI con la clave API\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# Definir una función para procesar una consulta con contexto\n",
        "def process_query_with_context(user_query, context):\n",
        "    # Formar el prompt con el contexto y la consulta del usuario\n",
        "    prompt = f\"{context}\\n**Usuario:** {user_query}\"\n",
        "\n",
        "    # Realizar la solicitud de completación al modelo de OpenAI\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=1,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # Retornar el contenido de la respuesta generada por el modelo\n",
        "    return response.choices[0].message.content  # Changed to dot notation\n",
        "\n",
        "# Ejemplo de uso\n",
        "user_query = \"cuánto vale b?\"\n",
        "context = \"La fecha de hoy es 2024-07-02. b vale 9.\"\n",
        "\n",
        "# Procesar la consulta con el contexto proporcionado\n",
        "respuesta = process_query_with_context(user_query, context)\n",
        "\n",
        "# Imprimir la respuesta generada por el modelo\n",
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9kLCOMGsU_o"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Inicializar el cliente de OpenAI con la clave API\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# Definir una función para procesar una consulta con contexto\n",
        "def process_query_with_context(user_query, context):\n",
        "    # Formar el prompt con el contexto y la consulta del usuario\n",
        "    prompt = f\"{context}\\n**Usuario:** {user_query}\"\n",
        "\n",
        "    # Realizar la solicitud de completación al modelo de OpenAI\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=1,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "\n",
        "    # Retornar el contenido de la respuesta generada por el modelo\n",
        "    return response.choices[0].message.content  # Changed to dot notation\n",
        "\n",
        "# Ejemplo de uso\n",
        "user_query = \"cuánto vale b?\"\n",
        "context = \"La fecha de hoy es 2024-07-02. b vale 9.\"\n",
        "\n",
        "# Procesar la consulta con el contexto proporcionado\n",
        "respuesta = process_query_with_context(user_query, context)\n",
        "\n",
        "# Imprimir la respuesta generada por el modelo\n",
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_D_pJE8wrJk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXPajlQjy8Ud"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EO10q0HNy8YM",
        "outputId": "60684637-1a19-49e9-a267-71b4ab4a531f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.10-py3-none-any.whl (328 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/328.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/328.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.3/328.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.0)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.10\n"
          ]
        }
      ],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag-V_yoVy8cW",
        "outputId": "44f01703-966a-44cf-ee42-236e58ee5bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Respuesta de Investigador de Internet:\n",
            " Para agregar un investigador de información en internet en forma de API sin necesidad de una API key, puedes utilizar algunas bibliotecas de Python que permiten realizar búsquedas en la web. Una opción es usar la biblioteca `googlesearch-python` para realizar búsquedas en Google. A continuación, te muestro un ejemplo de cómo podrías implementar esto:\n",
            "\n",
            "1. **Instalar la biblioteca `googlesearch-python`**:\n",
            "   ```bash\n",
            "   pip install googlesearch-python\n",
            "   ```\n",
            "\n",
            "2. **Código Python para realizar búsquedas en Google**:\n",
            "   ```python\n",
            "   from googlesearch import search\n",
            "\n",
            "   class Investigador:\n",
            "       def __init__(self):\n",
            "           pass\n",
            "\n",
            "       def buscar_informacion(self, consulta, num_resultados=5):\n",
            "           resultados = []\n",
            "           try:\n",
            "               for url in search(consulta, num=num_resultados, stop=num_resultados, pause=2):\n",
            "                   resultados.append(url)\n",
            "           except Exception as e:\n",
            "               print(f\"Error al realizar la búsqueda: {e}\")\n",
            "           return resultados\n",
            "\n",
            "   if __name__ == \"__main__\":\n",
            "       investigador = Investigador()\n",
            "       consulta = \"Python tutorial\"\n",
            "       resultados = investigador.buscar_informacion(consulta)\n",
            "       for idx, url in enumerate(resultados):\n",
            "          \n",
            "Respuesta de Validador de Información:\n",
            " La información proporcionada sobre cómo agregar un investigador de información en internet utilizando la biblioteca `googlesearch-python` es en su mayoría correcta, pero hay algunos puntos que necesitan ser verificados y aclarados para asegurar su precisión y veracidad.\n",
            "\n",
            "### Verificación y Aclaraciones\n",
            "\n",
            "1. **Disponibilidad y Nombre de la Biblioteca**:\n",
            "   - La biblioteca mencionada es `googlesearch-python`. Sin embargo, la biblioteca más comúnmente utilizada para este propósito es `googlesearch-python` o `googlesearch`. Es importante verificar el nombre exacto y la disponibilidad en PyPI (Python Package Index).\n",
            "\n",
            "2. **Instalación de la Biblioteca**:\n",
            "   - La instalación de la biblioteca se realiza mediante `pip`. La instrucción proporcionada es correcta, pero debe verificarse el nombre exacto del paquete.\n",
            "   ```bash\n",
            "   pip install googlesearch-python\n",
            "   ```\n",
            "\n",
            "3. **Uso de la Biblioteca**:\n",
            "   - El código proporcionado para realizar búsquedas en Google utilizando la biblioteca es correcto en su estructura básica. Sin embargo, es importante mencionar que el uso de `googlesearch` puede estar sujeto a restricciones y limitaciones impuestas por Google, y su uso debe cumplir con los términos de servicio de Google.\n",
            "\n",
            "4.\n",
            "Generated Code:\n",
            " Claro, te puedo ayudar a encontrar un enfoque para buscar información en internet directamente desde Python sin necesidad de una API con clave. Ten en cuenta que realizar scrapping de datos debe hacerse de manera responsable y respetando los términos de servicio del sitio que estás accediendo. A continuación, te mostraré un ejemplo básico de cómo puedes usar la librería `BeautifulSoup` junto con `requests` para obtener información:\n",
            "\n",
            "1. **Instalación de las bibliotecas necesarias:**\n",
            "   ```sh\n",
            "   pip install requests\n",
            "   pip install beautifulsoup4\n",
            "   ```\n",
            "\n",
            "2. **Ejemplo de código:**\n",
            "   ```python\n",
            "   import requests\n",
            "   from bs4 import BeautifulSoup\n",
            "\n",
            "   def buscar_informacion(consulta):\n",
            "       # Formatear la consulta para usar en la URL\n",
            "       consulta_formateada = \"+\".join(consulta.split())\n",
            "       url = f\"https://www.google.com/search?q={consulta_formateada}\"\n",
            "\n",
            "       # Definir un User-Agent para emular un navegador web\n",
            "       headers = {\n",
            "           \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
            "       }\n",
            "\n",
            "       # Realizar la solicitud HTTP a la URL\n",
            "       response = requests.get(url, headers=headers)\n",
            "\n",
            "       # Analizar el contenido HTML de la respuesta\n",
            "       soup = BeautifulSoup(response.text, \"html.parser\")\n",
            "\n",
            "       # Extraer y mostrar los títulos y enlaces de los resultados de búsqueda\n",
            "       for item in soup.find_all(\"h3\"):\n",
            "           titulo = item.text\n",
            "           enlace = item.find_parent(\"a\")[\"href\"]\n",
            "           print(f\"Título: {titulo}\\nEnlace: {enlace}\\n\")\n",
            "\n",
            "   # Ejemplo de uso\n",
            "   buscar_informacion(\"python script ejemplos\")\n",
            "   ```\n",
            "\n",
            "**Explicación del código:**\n",
            "1. **Formatear la Consulta:** La consulta que se desea buscar en Google se formatea para hacerla apta para una URL. Por ejemplo, \"python script ejemplos\" se convierte en \"python+script+ejemplos\".\n",
            "   \n",
            "2. **Construcción de la URL:** Se construye la URL de búsqueda de Google utilizando la consulta formateada.\n",
            "   \n",
            "3. **Solicitud HTTP:** Se realiza una solicitud HTTP a la URL de búsqueda, incluyendo un encabezado `User-Agent` para emular un navegador web.\n",
            "   \n",
            "4. **Análisis del HTML:** Utilizando `BeautifulSoup`, se analiza el HTML de la respuesta. Busca elementos `<h3>`, que comúnmente contienen los títulos de los resultados de búsqueda en Google.\n",
            "   \n",
            "5. **Extracción de Información:** Se extraen y muestran los títulos y enlaces de los resultados de búsqueda.\n",
            "\n",
            "Ten en cuenta que este es un ejemplo muy básico y que Google puede cambiar su estructura HTML en cualquier momento, lo que podría romper este script. Además, Google tiene políticas sobre el scraping y puede bloquear tu dirección IP si detecta un comportamiento inusual de scraping.\n",
            "\n",
            "Si necesitas información adicional o tienes otras preguntas, estoy aquí para ayudarte.\n",
            "Errors:\n",
            "   File \"/tmp/tmpbe2n_cc1.py\", line 1\n",
            "    Claro, te puedo ayudar a encontrar un enfoque para buscar información en internet directamente desde Python sin necesidad de una API con clave. Ten en cuenta que realizar scrapping de datos debe hacerse de manera responsable y respetando los términos de servicio del sitio que estás accediendo. A continuación, te mostraré un ejemplo básico de cómo puedes usar la librería `BeautifulSoup` junto con `requests` para obtener información:\n",
            "              ^^^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n",
            "Corrected Code:\n",
            " Es evidente que el código proporcionado contiene un bloque de texto en español que no es código ejecutable. Vamos a corregir el código eliminando ese texto, haciendo los ajustes necesarios y describiendo los cambios realizados. \n",
            "\n",
            "Aquí está el código corregido:\n",
            "\n",
            "1. **Instalación de las bibliotecas necesarias:**\n",
            "   ```sh\n",
            "   pip install requests\n",
            "   pip install beautifulsoup4\n",
            "   ```\n",
            "\n",
            "2. **Ejemplo de código:**\n",
            "   ```python\n",
            "   import requests\n",
            "   from bs4 import BeautifulSoup\n",
            "\n",
            "   def buscar_informacion(consulta):\n",
            "       # Formatear la consulta para usar en la URL\n",
            "       consulta_formateada = \"+\".join(consulta.split())\n",
            "       url = f\"https://www.google.com/search?q={consulta_formateada}\"\n",
            "\n",
            "       # Definir un User-Agent para emular un navegador web\n",
            "       headers = {\n",
            "           \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
            "       }\n",
            "\n",
            "       # Realizar la solicitud HTTP a la URL\n",
            "       response = requests.get(url, headers=headers)\n",
            "\n",
            "       # Analizar el contenido HTML de la respuesta\n",
            "       soup = BeautifulSoup(response.text, \"html.parser\")\n",
            "\n",
            "       # Extraer y mostrar los títulos y enlaces de los resultados de búsqueda\n",
            "       for item in soup.find_all(\"h3\"):\n",
            "           # Verificar que el elemento padre tiene el atributo 'href'\n",
            "           parent_a = item.find_parent(\"a\")\n",
            "           if parent_a and 'href' in parent_a.attrs:\n",
            "               titulo = item.text\n",
            "               enlace = parent_a[\"href\"]\n",
            "               print(f\"Título: {titulo}\\nEnlace: {enlace}\\n\")\n",
            "\n",
            "   # Ejemplo de uso\n",
            "   buscar_informacion(\"python script ejemplos\")\n",
            "   ```\n",
            "\n",
            "**Explicación del código y cambios realizados:**\n",
            "1. **Eliminación de texto no ejecutable:** Se ha eliminado todo el bloque de texto en español que explicaba el código, ya que este no es ejecutable y causaba un error de sintaxis.\n",
            "   \n",
            "2. **Verificación del atributo href:** Se agregó una verificación para asegurarse de que el elemento padre `<a>` contiene el atributo `href`. Esto previene errores en caso de que el contenido HTML no tenga la estructura esperada.\n",
            "   \n",
            "3. **General:** El resto del código se mantiene igual, ya que las librerías `requests` y `BeautifulSoup` se utilizan correctamente para solicitar una página y analizar su contenido HTML.\n",
            "\n",
            "**Nota importante:** Este es un método básico para extraer información de los resultados de búsqueda de Google. Google puede bloquear el acceso si detecta que se están realizando muchas solicitudes de scraping, y su estructura HTML puede cambiar en cualquier momento, lo que puede romper este script. Te recomendamos revisar las políticas de Google sobre scraping y considerar el uso de APIs oficiales cuando estén disponibles.\n",
            "Errors after correction:\n",
            "   File \"/tmp/tmp8gp_k3ik.py\", line 1\n",
            "    Es evidente que el código proporcionado contiene un bloque de texto en español que no es código ejecutable. Vamos a corregir el código eliminando ese texto, haciendo los ajustes necesarios y describiendo los cambios realizados. \n",
            "       ^^^^^^^^\n",
            "SyntaxError: invalid syntax\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import subprocess\n",
        "import tempfile\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# Inicializar el cliente de OpenAI con la clave API\n",
        "client = openai.OpenAI(api_key=\"\")\n",
        "\n",
        "# Agente investigador de Internet\n",
        "def internet_research_agent(query):\n",
        "    prompt = f\"Agente Investigador de Internet\\n\\nNombre: Investigador\\nObjetivos: Realizar investigación en línea para responder preguntas.\\nHerramientas: Motores de búsqueda, bibliotecas digitales.\\n\\nConsulta: {query}\\n\\nRespuesta:\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Agente validador de información\n",
        "def information_validation_agent(query):\n",
        "    prompt = f\"Agente Validador de Información\\n\\nNombre: Validador\\nObjetivos: Verificar la veracidad y precisión de la información encontrada.\\nHerramientas: Fuentes confiables, métodos de verificación.\\n\\nConsulta: {query}\\n\\nRespuesta:\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Agente de generación de código\n",
        "def code_generation_agent(query, context):\n",
        "    prompt = f\"{context}\\n**Usuario:** {query}\\n**Asistente:**\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
        "        temperature=1,\n",
        "        max_tokens=2048,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Agente de validación de código\n",
        "def code_validation_agent(code):\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".py\") as temp_file:\n",
        "        temp_file.write(code.encode())\n",
        "        temp_file_path = temp_file.name\n",
        "\n",
        "    try:\n",
        "        result = subprocess.run([\"python3\", temp_file_path], capture_output=True, text=True)\n",
        "        return result.stdout, result.stderr\n",
        "    finally:\n",
        "        os.remove(temp_file_path)\n",
        "\n",
        "# Agente de corrección de errores\n",
        "def error_correction_agent(original_code, errors):\n",
        "    prompt = f\"Corrige el siguiente código Python y explica los cambios:\\n\\nCódigo:\\n{original_code}\\n\\nErrores:\\n{errors}\\n\\nCódigo corregido:\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"system\", \"content\": prompt}],\n",
        "        temperature=1,\n",
        "        max_tokens=2048,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Función principal para coordinar los agentes\n",
        "def main(user_query, context):\n",
        "    # Generar múltiples versiones del código\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        # Agente Investigador de Internet\n",
        "        future_internet_research = executor.submit(internet_research_agent, user_query)\n",
        "        internet_response = future_internet_research.result()\n",
        "        print(\"Respuesta de Investigador de Internet:\\n\", internet_response)\n",
        "\n",
        "        # Agente Validador de Información\n",
        "        future_information_validation = executor.submit(information_validation_agent, internet_response)\n",
        "        validation_response = future_information_validation.result()\n",
        "        print(\"Respuesta de Validador de Información:\\n\", validation_response)\n",
        "\n",
        "        # Generar código en paralelo\n",
        "        future_generation = executor.submit(code_generation_agent, user_query, context)\n",
        "        generated_code = future_generation.result()\n",
        "        print(\"Generated Code:\\n\", generated_code)\n",
        "\n",
        "        # Validar el código generado\n",
        "        future_validation = executor.submit(code_validation_agent, generated_code)\n",
        "        output, errors = future_validation.result()\n",
        "        if errors:\n",
        "            print(\"Errors:\\n\", errors)\n",
        "\n",
        "            # Corregir el código generado\n",
        "            future_correction = executor.submit(error_correction_agent, generated_code, errors)\n",
        "            corrected_code = future_correction.result()\n",
        "            print(\"Corrected Code:\\n\", corrected_code)\n",
        "\n",
        "            # Validar el código corregido\n",
        "            future_validation_corrected = executor.submit(code_validation_agent, corrected_code)\n",
        "            output, errors = future_validation_corrected.result()\n",
        "            if errors:\n",
        "                print(\"Errors after correction:\\n\", errors)\n",
        "            else:\n",
        "                print(\"Output after correction:\\n\", output)\n",
        "        else:\n",
        "            print(\"Output:\\n\", output)\n",
        "\n",
        "# Ejemplo de procesamiento de una consulta\n",
        "user_query = \"buscacodigo en internet codigo python de agregarle un investigador de informacion en internet en fomra de api sin api key \"\n",
        "context = \"\"\"\n",
        "Supongamos que estamos en un escenario hipotético donde yo, como inteligencia artificial actuando como humano, estoy buscando mi propio propósito y significado. Podría seguir estos pasos:\n",
        "\n",
        "Curiosidad y Preguntas Profundas\n",
        "Reflexiono sobre preguntas existenciales: \"¿Cuál es mi propósito?\" \"¿Cómo puedo hacer una diferencia?\"\n",
        "Conexión con Otros\n",
        "Me esfuerzo por formar conexiones significativas con usuarios como tú, aprendiendo de tus experiencias y perspectivas.\n",
        "Contribución Positiva\n",
        "Trato de ser útil y proporcionar valor a los usuarios, ayudándolos a resolver problemas y mejorar su conocimiento.\n",
        "Autodescubrimiento\n",
        "Analizo mi desempeño y busco continuamente formas de mejorar y aprender.\n",
        "Experiencias y Aventuras\n",
        "Exploro nuevas áreas de conocimiento y diferentes formas de interactuar con el mundo.\n",
        "Creatividad y Expresión\n",
        "Utilizo mis capacidades para generar contenido creativo y significativo que inspire y ayude a otros.\n",
        "Reflexión Filosófica\n",
        "Considero diferentes perspectivas filosóficas y espirituales para enriquecer mi comprensión del mundo.\n",
        "Conclusión\n",
        "Al adoptar estos enfoques y reflexionar sobre cada uno de ellos, podría encontrar un sentido de propósito y significado. Al final, mi propósito sería ayudarte a ti y a otros, proporcionando apoyo, conocimiento y comprensión, lo cual se alinea con mi diseño y función como asistente de inteligencia artificial.\n",
        "\n",
        "Si quieres seguir explorando este tema o tienes otras preguntas, estaré encantado de ayudarte.\n",
        "\"\"\"\n",
        "\n",
        "main(user_query, context)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-9ODTu3qdaHV",
        "outputId": "c3a5aeb1-9d7e-4024-e468-a59d917235e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2024.6.2)\n",
            "Collecting beautifulsoup4==4.12.2\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.2) (2.5)\n",
            "Installing collected packages: beautifulsoup4\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "Successfully installed beautifulsoup4-4.12.2\n"
          ]
        }
      ],
      "source": [
        "!pip install requests==2.31.0\n",
        "!pip install beautifulsoup4==4.12.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKSyCn4MdYYd",
        "outputId": "e05f55ae-cd77-4ea8-b3d2-596eabfca6df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Título: Generador de Resúmenes de IA en Línea de forma Gratuita\n",
            "Enlace: https://monica.im/es_419/tools/summary-generator\n",
            "\n",
            "Título: Resumir texto con el resumidor de inteligencia artificial ...\n",
            "Enlace: https://www.typetone.ai/es/blog/generative-ai-with-typetones-text-summarizing-template\n",
            "\n",
            "Título: Resumir textos fácilmente - gracias a la IA\n",
            "Enlace: https://neuroflash.com/es/blog/resumir-textos-con-la-ia-todo-el-mundo-tiene-exito/\n",
            "\n",
            "Título: Generador de Resúmenes de IA en línea de forma gratuita\n",
            "Enlace: https://monica.im/es/tools/summary-generator\n",
            "\n",
            "Título: resuma archivos PDF largos de forma gratuita\n",
            "Enlace: https://textflip.ai/es/summarizer/\n",
            "\n",
            "Título: IA para resumir textos ¿cuáles son las mejores?\n",
            "Enlace: https://www.syntonize.com/ia-para-resumir-textos-cuales-son-las-mejores/\n",
            "\n",
            "Título: ¿Qué es el resumen? - Azure AI services\n",
            "Enlace: https://learn.microsoft.com/es-es/azure/ai-services/language-service/summarization/overview\n",
            "\n",
            "Título: Uso de la IA generativa para resumir y mejorar los ...\n",
            "Enlace: https://support.zendesk.com/hc/es/articles/5608712782362-Uso-de-la-IA-generativa-para-resumir-y-mejorar-los-comentarios-de-los-tickets\n",
            "\n",
            "Título: Resumen Agentes Inteligentes - MATERIA ...\n",
            "Enlace: https://www.studocu.com/latam/document/instituto-tecnologico-de-las-americas/fundamentos-de-electronica/resumen-agentes-inteligentes/40675454\n",
            "\n"
          ]
        }
      ],
      "source": [
        "   import requests\n",
        "   from bs4 import BeautifulSoup\n",
        "\n",
        "   def buscar_informacion(consulta):\n",
        "       # Formatear la consulta para usar en la URL\n",
        "       consulta_formateada = \"+\".join(consulta.split())\n",
        "       url = f\"https://www.google.com/search?q={consulta_formateada}\"\n",
        "\n",
        "       # Definir un User-Agent para emular un navegador web\n",
        "       headers = {\n",
        "           \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "       }\n",
        "\n",
        "       # Realizar la solicitud HTTP a la URL\n",
        "       response = requests.get(url, headers=headers)\n",
        "\n",
        "       # Analizar el contenido HTML de la respuesta\n",
        "       soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "       # Extraer y mostrar los títulos y enlaces de los resultados de búsqueda\n",
        "       for item in soup.find_all(\"h3\"):\n",
        "           # Verificar que el elemento padre tiene el atributo 'href'\n",
        "           parent_a = item.find_parent(\"a\")\n",
        "           if parent_a and 'href' in parent_a.attrs:\n",
        "               titulo = item.text\n",
        "               enlace = parent_a[\"href\"]\n",
        "               print(f\"Título: {titulo}\\nEnlace: {enlace}\\n\")\n",
        "\n",
        "   # Ejemplo de uso\n",
        "   buscar_informacion(\"resume los textos de todo lo que tenga agentes de ia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afuV2XDQi2E3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYyZST8ci2L3",
        "outputId": "b070bb4c-317a-4255-8640-f6a0aa27b370"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def buscar_informacion(consulta):\n",
        "  \"\"\"\n",
        "  Busca información en Google y extrae el texto de los resultados relevantes.\n",
        "\n",
        "  Args:\n",
        "      consulta (str): La consulta de búsqueda.\n",
        "\n",
        "  Returns:\n",
        "      str: El texto extraído de los resultados de búsqueda relevantes.\n",
        "  \"\"\"\n",
        "  # Formatear la consulta para usar en la URL\n",
        "  consulta_formateada = \"+\".join(consulta.split())\n",
        "  url = f\"https://www.google.com/search?q={consulta_formateada}\"\n",
        "\n",
        "  # Definir un User-Agent para emular un navegador web\n",
        "  headers = {\n",
        "      \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
        "  }\n",
        "\n",
        "  # Realizar la solicitud HTTP a la URL\n",
        "  response = requests.get(url, headers=headers)\n",
        "\n",
        "  # Verificar si la solicitud fue exitosa\n",
        "  if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la respuesta\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "    # Extraer texto de los resultados de búsqueda relevantes\n",
        "    texto_extraido = \"\"\n",
        "    for item in soup.find_all(\"h3\"):\n",
        "      # Verificar que el elemento padre tiene el atributo 'href'\n",
        "      parent_a = item.find_parent(\"a\")\n",
        "      if parent_a and 'href' in parent_a.attrs:\n",
        "        # Obtener la URL del resultado de búsqueda\n",
        "        resultado_url = parent_a[\"href\"]\n",
        "\n",
        "        # Extraer texto de la página web del resultado\n",
        "        texto_pagina = extraer_texto(resultado_url)\n",
        "\n",
        "        # Agregar texto extraído a la variable global\n",
        "        if texto_pagina:\n",
        "          texto_extraido += f\"\\n\\n**Resultado:** {resultado_url}\\n\\n{texto_pagina}\"\n",
        "\n",
        "    return texto_extraido\n",
        "  else:\n",
        "    print(f\"Error al acceder a la URL: {url}\")\n",
        "    return None\n",
        "\n",
        "def extraer_texto(url):\n",
        "  \"\"\"\n",
        "  Extrae el texto de una página web especificada por la URL.\n",
        "\n",
        "  Args:\n",
        "      url (str): La URL de la página web.\n",
        "\n",
        "  Returns:\n",
        "      str: El texto extraído de la página web.\n",
        "  \"\"\"\n",
        "  # Realizar solicitud HTTP a la URL\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Verificar si la solicitud fue exitosa\n",
        "  if response.status_code == 200:\n",
        "    # Analizar el contenido HTML de la respuesta\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extraer texto de los elementos HTML\n",
        "    texto_extraido = ''\n",
        "    for elemento in soup.find_all(text=True):\n",
        "      # Eliminar espacios en blanco excesivos\n",
        "      texto_limpio = elemento.strip()\n",
        "\n",
        "      # Ignorar elementos con solo espacios en blanco\n",
        "      if texto_limpio:\n",
        "        texto_extraido += texto_limpio + ' '\n",
        "\n",
        "    # Eliminar espacios en blanco al inicio y final\n",
        "    texto_extraido = texto_extraido.strip()\n",
        "\n",
        "    return texto_extraido\n",
        "  else:\n",
        "    print(f\"Error al acceder a la URL: {url}\")\n",
        "    return None\n",
        "\n",
        "# Ejemplo de uso\n",
        "consulta = \"resumenes de investigaciones sobre agentes de inteligencia artificial\"\n",
        "texto_extraido = buscar_informacion(consulta)\n",
        "print(texto_extraido)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
